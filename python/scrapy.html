<hr>
<p>title: Python 爬虫 —— Scrapy<br>date: 2020-7-1 15:41:43<br>tags:</p>
<ul>
<li>Python</li>
<li>Scrapy</li>
<li>爬虫<br>category:</li>
<li>Python<br>mathjax: true</li>
</ul>
<hr>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p><img src="https://lyh543.coding.net/p/pic-bed/d/pic-bed/git/raw/master/28cf998153f11ab7a5b1579d5eccc122deb0ea3f8b1bf12c6fd177594f264039.png" alt="爬虫原理"></p>
<p>流程如下：</p>
<ul>
<li><strong>爬虫</strong>告诉<strong>引擎</strong>，需要爬取哪些链接 <code>urls</code></li>
<li>引擎把链接发给<strong>调度器</strong></li>
<li>调度器收到链接后，进入<strong>队列</strong></li>
<li>调度器从队列里取出链接，告诉<strong>下载器</strong>开始下载</li>
<li>下载完毕后，把结果交给爬虫</li>
<li>爬虫把结果中取回数据，交给<strong>管道</strong></li>
<li>管道将数据存储到 MySQL/文本文件等</li>
</ul>
<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>安装 Python 3 后，</p>
<pre><code>pip3 install scrapy</code></pre><p>（可选）在本地安装 Redis 数据库，端口 <code>5376</code>，用户名 <code>root</code>，密码 <code>123456</code>；然后安装 Python 调用 Redis 的库：</p>
<pre><code>pip3 install redis</code></pre><h2 id="简单爬虫"><a href="#简单爬虫" class="headerlink" title="简单爬虫"></a>简单爬虫</h2><p>这里针对一个列表的网页爬取其列表内容，示例为 <a href="https://mobile.ithome.com/">https://mobile.ithome.com/</a> 的新闻标题、链接等信息。</p>
<h3 id="建立目录"><a href="#建立目录" class="headerlink" title="建立目录"></a>建立目录</h3><p>第一步，建立项目。</p>
<pre><code class="sh">scrapy startproject my_spider D:\  <span class="comment"># 建立项目</span></code></pre>
<p>会建立如下目录：</p>
<pre><code>my_spider/
    scrapy.cfg
    my_spider/
        __init__.py
        items.py
        pipelines.py
        settings.py
        spiders/
            __init__.py
            ...</code></pre><p>然后可以在 PyCharm 中打开 <code>D:\my_spider</code>。</p>
<p>其中，<code>settings.py</code> 中 <code>ROBOTSTXT_OBEY = True</code> 表示会自觉遵守页面规定，如果不让爬虫则不会进行爬虫。</p>
<h3 id="生成爬虫代码"><a href="#生成爬虫代码" class="headerlink" title="生成爬虫代码"></a>生成爬虫代码</h3><p>第二步，切换目录，然后生成一个爬虫：</p>
<pre><code class="sh"><span class="built_in">cd</span> /d D:\my_spider
scrapy genspider ithome mobile.ithome.com <span class="comment"># 生成爬虫</span></code></pre>
<p>此时 <code>D:\my_spider\my_spider\spiders</code> 下会自动生成 <code>ithome.py</code>，内容如下：</p>
<pre><code class="py"><span class="keyword">import</span> scrapy

<span class="class"><span class="keyword">class</span> <span class="title">IthomeSpider</span><span class="params">(scrapy.Spider)</span>:</span>
    name = <span class="string">'ithome'</span>
    allowed_domains = [<span class="string">'mobile.ithome.com'</span>]
    start_urls = [<span class="string">'http://mobile.ithome.com/'</span>]

    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span> <span class="comment"># 解析 (parse) 网页的方法</span>
        <span class="keyword">pass</span></code></pre>
<p>这里可以将 <code>start_urls</code> 链接改为 <code>https</code>。</p>
<h3 id="定义数据结构"><a href="#定义数据结构" class="headerlink" title="定义数据结构"></a>定义数据结构</h3><p>第三步，定义数据结构。这里没有直接使用 Python 原生的继承于 <code>object</code> 的 <code>class</code>，而是选择继承 <code>scrapy.Item</code> 的类。这样定义的数据结构，更方便 Scrapy 处理。定义放在 <code>D:\my_spider\my_spider\items.py</code>。</p>
<pre><code class="py"><span class="keyword">import</span> scrapy

<span class="class"><span class="keyword">class</span> <span class="title">IthomeData</span><span class="params">(scrapy.Item)</span>:</span>
    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span>
        title = scrapy.Field()
        time = scrapy.Field()
        abstract = scrapy.Field()
        url = scrapy.Field()</code></pre>
<h3 id="解析网站"><a href="#解析网站" class="headerlink" title="解析网站"></a>解析网站</h3><p>第四步，定义数据结构后，开始解析爬虫获得的数据。爬虫本质获得的是 <code>start_urls</code> 对应的 html 文件， 然后解析 html，将解析到的数据进行处理。</p>
<p>我们用 Chrome 打开 <a href="https://mobile.ithome.com/，右键一个标题并“检查”，可以看到该">https://mobile.ithome.com/，右键一个标题并“检查”，可以看到该</a> HTML 的结构。</p>
<p><img src="https://lyh543.coding.net/p/pic-bed/d/pic-bed/git/raw/master/b1309aaf05e0ad49970483f90cb77c7617a5e269fb19144b6e8f24153b75939b.png" alt="mobile.ithome.com 详情"></p>
<p>同时，在命令行执行 <code>scrapy shell https://mobile.ithome.com/</code>。看到以下输出：</p>
<pre><code>2020-07-01 16:55:01 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET https://mobile.ithome.com/&gt; (referer: None)
2020-07-01 16:55:02 [asyncio] DEBUG: Using proactor: IocpProactor
[s] Available Scrapy objects:
[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)
[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x000001AEBC19F0A0&gt;
[s]   item       {}
[s]   request    &lt;GET https://mobile.ithome.com/&gt;
[s]   response   &lt;200 https://mobile.ithome.com/&gt;
[s]   settings   &lt;scrapy.settings.Settings object at 0x000001AEBC19BC70&gt;
[s]   spider     &lt;DefaultSpider &apos;default&apos; at 0x1aebc4e6730&gt;
[s] Useful shortcuts:
[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)
[s]   fetch(req)                  Fetch a scrapy.Request and update local objects
[s]   shelp()           Shell help (print this help)
[s]   view(response)    View response in a browser
2020-07-01 16:55:02 [asyncio] DEBUG: Using proactor: IocpProactor
In [1]:</code></pre><p><code>200</code> 表示正常。输入 <code>response</code> 并回车：</p>
<pre><code class="py">In [<span class="number">1</span>]: response
Out[<span class="number">1</span>]: &lt;<span class="number">200</span> https://mobile.ithome.com/&gt;</code></pre>
<p>接下来解析 <code>response</code>。解析的方法是使用 <code>xpath</code>。</p>
<blockquote>
<p><code>XPath</code> 即为 XML 路径语言，它是一种用来确定 XML 文档中某部分位置的计算机语言。XPath 基于 XML 的树状结构，提供在数据结构树中找寻节点的能力。</p>
</blockquote>
<p>在 Chrome 中右键想要爬取的第一个标题，然后 Copy Xpath，如下图：</p>
<p><img src="https://lyh543.coding.net/p/pic-bed/d/pic-bed/git/raw/master/31a4adde7ff3bd0d994afb68289034839baecd7b1b62ea959f5a33c4ecdccd0c.png" alt="获取 Xpath"></p>
<p>然后作为 <code>response</code> 的 <code>xpath</code> 成员函数的参数，执行，结果如下，如果输出不是 <code>[]</code> 则正确。使用 <code>extract_first</code> 看到其内容。</p>
<pre><code class="py">In [<span class="number">12</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li[1]/div/h2/a'</span>)
Out[<span class="number">12</span>]: [&lt;Selector xpath=<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li[1]/div/h2/a'</span> data=<span class="string">'&lt;a href="https://www.ithome.com/0/491...'</span>&gt;]

In [<span class="number">14</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li[1]/div/h2/a'</span>).extract_first()
Out[<span class="number">14</span>]: <span class="string">'&lt;a href="https://www.ithome.com/0/491/113.htm" target="_blank"&gt;小米NFC碰碰贴要回来了？小米高管：大家喜欢的话我们就做&lt;/a&gt;'</span></code></pre>
<p>可以看到，标题已经出来了，并且和前面的图是一致的。</p>
<p>然后尝试找到遍历的方法。html 里，<code>ul</code> 是列表（<code>unordered list</code>），下面的每一个元素为 <code>li</code>（<code>list item</code>）。将上面的 Xpath 从 <code>li</code> 分开，因为我们需要在 Python 中遍历每个元素。注意在 Xpath 中下标从 1 开始，而在 Python 中下标从 0 开始。</p>
<pre><code class="py">In [<span class="number">16</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li'</span>)[<span class="number">0</span>].xpath(<span class="string">'./div/h2/a'</span>).extract_first() <span class="comment"># 注意第二个 Xpath 的开头有个 .</span>
Out[<span class="number">16</span>]: <span class="string">'&lt;a href="https://www.ithome.com/0/491/113.htm" target="_blank"&gt;小米NFC碰碰贴要回来了？小米高管：大家喜欢的话我们就做&lt;/a&gt;'</span>
In [<span class="number">17</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li'</span>)[<span class="number">1</span>].xpath(<span class="string">'./div/h2/a'</span>).extract_first() <span class="comment"># 测试下一篇文章是否也是对应的</span>
Out[<span class="number">17</span>]: <span class="string">'&lt;a href="https://www.ithome.com/0/491/111.htm" target="_blank"&gt;荣耀30系列强势霸榜618，蝉联多日销量冠军，立减300仅要2699起&lt;/a&gt;'</span></code></pre>
<p>再进一步获取其文本和链接，使用 <code>text()</code> 函数和 <code>@href</code>：</p>
<pre><code class="py">In [<span class="number">18</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li'</span>)[<span class="number">0</span>].xpath(<span class="string">'./div/h2/a/text()'</span>).extract_first()
Out[<span class="number">18</span>]: <span class="string">'小米NFC碰碰贴要回来了？小米高管：大家喜欢的话我们就做'</span>
In [<span class="number">36</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li'</span>)[<span class="number">0</span>].xpath(<span class="string">'./div/h2/a/@href'</span>).extract_first()
Out[<span class="number">36</span>]: <span class="string">'https://www.ithome.com/0/491/113.htm'</span></code></pre>
<p>用同样的方法可以获取其时间、摘要：</p>
<pre><code class="py">In [<span class="number">41</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li'</span>)[<span class="number">0</span>].xpath(<span class="string">'./div/div/p'</span>).extract_first()
Out[<span class="number">41</span>]: <span class="string">'&lt;p&gt;小米早前曾发布了一款名为“小米NFC碰碰贴”的产品。今日小米集团智能硬件部总经理刘新宇表示，当时碰碰贴概念太超前，如今大家喜欢，“那我们就做新版碰碰贴”。似乎也在暗示小米NFC碰碰贴产品即将回归&lt;/p&gt;'</span>
In [<span class="number">48</span>]: response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li'</span>)[<span class="number">0</span>].xpath(<span class="string">'./div/h2/span/text()'</span>).extract_first()
Out[<span class="number">48</span>]: <span class="string">'今日 17:35'</span></code></pre>
<p>到这里就已经成功一半了。</p>
<h3 id="编写解析函数"><a href="#编写解析函数" class="headerlink" title="编写解析函数"></a>编写解析函数</h3><blockquote>
<p><code>parse()</code> 是 <code>spider</code> 的一个方法。 被调用时，每个初始 URL 完成下载后生成的 <code>Response</code> 对象将会作为唯一的参数传递给该函数。 该方法负责解析返回的数据(<code>response data</code>)，提取数据(生成<code>item</code>)以及生成需要进一步处理的 URL 的 <code>Request</code> 对象。</p>
</blockquote>
<p>回到 <code>D:\my_spider\my_spider\spiders\ithome.py</code>，编写 <code>parse</code> 成员函数。<code>parse</code> 函数的思想就是，遍历 <code>ul</code> 的 <code>li</code>，取出我们需要的信息存进 <code>item</code>，然后返回 <code>item</code>。这里直接上代码。</p>
<pre><code class="py"><span class="comment"># ithome.py</span>

<span class="keyword">import</span> scrapy
<span class="keyword">from</span> my_spider.items <span class="keyword">import</span> IthomeData

<span class="class"><span class="keyword">class</span> <span class="title">IthomeSpider</span><span class="params">(scrapy.Spider)</span>:</span>
    name = <span class="string">'ithome'</span>
    allowed_domains = [<span class="string">'mobile.ithome.com'</span>]
    start_urls = [<span class="string">'https://mobile.ithome.com/'</span>]

    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span>
        li_list = response.xpath(<span class="string">'//*[@id="wrapper"]/div[1]/div[3]/ul[1]/li'</span>)
        item_list = []
        <span class="keyword">for</span> li <span class="keyword">in</span> li_list:
            item = IthomeData()
            item[<span class="string">"title"</span>] = li.xpath(<span class="string">'./div/h2/a/text()'</span>).extract_first()
            item[<span class="string">"url"</span>] = li.xpath(<span class="string">'./div/h2/a/@href'</span>).extract_first()
            item[<span class="string">"abstract"</span>] = li.xpath(<span class="string">'./div/div/p'</span>).extract_first()
            item[<span class="string">"time"</span>] = li.xpath(<span class="string">'./div/h2/span/text()'</span>).extract_first()
            item_list.append(item)

        <span class="keyword">return</span> item_list</code></pre>
<p>注意，<code>import</code> 引入 <code>item</code> 的方式有点不一样，这里是 <code>from my_spider.items import IthomeData</code>。</p>
<h3 id="编写管道"><a href="#编写管道" class="headerlink" title="编写管道"></a>编写管道</h3><p>管道则是将上面 <code>parse</code> 函数的解析出来的 <code>item_list</code> 进行处理、存储。这里为简化代码，直接输出；当然也可以写入文本文件、存储到数据库等。代码如下：</p>
<pre><code class="py"><span class="comment"># pipelines.py</span>
<span class="class"><span class="keyword">class</span> <span class="title">MySpiderPipeline</span>:</span>
    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span>
        print(item)</code></pre>
<h3 id="运行爬虫"><a href="#运行爬虫" class="headerlink" title="运行爬虫"></a>运行爬虫</h3><p>最后的最后，运行爬虫。可以直接在 <code>D:\my_spider\my_spider</code> 目录下运行 <code>scrapy crawl ithome</code>，也可以在该目录下编写以下 <code>python</code> 代码并运行。</p>
<pre><code class="py"><span class="keyword">from</span> scrapy.cmdline <span class="keyword">import</span> execute

execute(<span class="string">'scrapy crawl ithome'</span>.split(<span class="string">' '</span>))</code></pre>
<p>如果部分输出如下则正常（IT 之家貌似爬虫和直接访问得到的 HTML 不一样？可能做了防爬虫。至少方法是对的）。</p>
<pre><code>{&apos;abstract&apos;: &apos;&lt;p&gt;今天小米10 Pro手机正式推送MIUI 12.0.1稳定版更新，并且不是稳定版内测，这意味着小米10 &apos;
             &apos;Pro手机普通用户也可以方便升级MIUI 12.0.1稳定版系统了。&lt;/p&gt;&apos;,
 &apos;time&apos;: &apos;今日 23:09&apos;,
 &apos;title&apos;: &apos;小米 10 Pro 正式推送 MIUI 12 稳定版&apos;,
 &apos;url&apos;: &apos;https://www.ithome.com/0/493/559.htm&apos;}
2020-07-01 18:20:38 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 https://mobile.ithome.com/&gt;
{&apos;abstract&apos;: &apos;&lt;p&gt;今日消息人士Jon_Prosser也曝光了代号为C68的苹果AirPower充电板原型机的真机照：此次曝光的AirPower充电板似乎解决了
过热问题，其已可满足AirPods &apos;
             &apos;Pro和一块Apple Watch同时充电&lt;/p&gt;&apos;,
 &apos;time&apos;: &apos;今日 22:37&apos;,
 &apos;title&apos;: &apos;苹果AirPower充电板原型机曝光！Apple Watch/AirPods可一起充电&apos;,
 &apos;url&apos;: &apos;https://www.ithome.com/0/493/555.htm&apos;}</code></pre>